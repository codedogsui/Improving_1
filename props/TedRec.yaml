n_layers: 2
n_heads: 2
hidden_size: 300
inner_size: 256
hidden_dropout_prob: 0.6
attn_dropout_prob: 0.6
hidden_act: 'gelu'
layer_norm_eps: 1e-12
initializer_range: 0.05
loss_type: 'CE'

plm_suffix: feat1CLS
plm_size: 768
max_seq_length: 50
adaptor_dropout_prob: 0.4
adaptor_layers: [768,300]
noise: True
temperature: 0.09
n_exps: 8
data_args:
order: TO
